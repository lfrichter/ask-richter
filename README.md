# Ask Richter - Meu CV Interativo com IA

[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Express.js](https://img.shields.io/badge/Express.js-000000?style=for-the-badge&logo=express&logoColor=white)](https://expressjs.com/)
[![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://reactjs.org/)
[![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.com/)
[![Turborepo](https://img.shields.io/badge/Turborepo-EF4444?style=for-the-badge&logo=turborepo&logoColor=white)](https://turbo.build/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Vercel](https://img.shields.io/badge/Vercel-000000?style=for-the-badge&logo=vercel&logoColor=white)](https://vercel.com/)
![Render](https://img.shields.io/badge/Render-46E3B7?logo=render&logoColor=white&style=for-the-badge)

Este projeto transforma um curr√≠culo tradicional em uma experi√™ncia de di√°logo. O **Ask Richter** √© um chatbot especialista na minha trajet√≥ria profissional, permitindo que recrutadores e l√≠deres t√©cnicos fa√ßam perguntas em linguagem natural e recebam respostas inteligentes e contextuais, baseadas nos meus dados profissionais consolidados.

Mais do que um portf√≥lio, √© uma ferramenta de marketing profissional e uma demonstra√ß√£o pr√°tica de compet√™ncias em arquitetura de software moderna, desenvolvimento full-stack e integra√ß√£o com IA.

## üöÄ Principais Features

- **Interface de Chat Conversacional:** Uma UI limpa e reativa para um di√°logo fluido.
- **Respostas Contextuais com RAG:** Utiliza a t√©cnica de Retrieval-Augmented Generation, buscando informa√ß√µes em um banco vetorial **FAISS** para gerar respostas precisas.
- **Suporte a LLMs Locais com Ollama:** Configurado por padr√£o para rodar com modelos de linguagem locais (ex: Llama 3), permitindo testes e uso sem custo e com total privacidade.
- **Arquitetura Full-Stack Moderna:** Backend em Node.js/Express e Frontend em Next.js, ambos com TypeScript.
- **Estrutura em Monorepo:** Organizado com Turborepo para um desenvolvimento integrado e eficiente.


## ‚òÅÔ∏è Arquitetura na Nuvem

Este diagrama √© uma vis√£o geral, mostrando a intera√ß√£o entre os principais servi√ßos de nuvem.

```mermaid
graph TD
    subgraph "Usu√°rio"
        User[üë®‚Äçüíª Usu√°rio no Navegador]
    end

    subgraph "Nuvem Vercel"
        Frontend["‚öõÔ∏è Frontend (Next.js)<br>ask-richter.vercel.app"]
    end

    subgraph "Nuvem Render.com"
        Backend["‚öôÔ∏è Backend (Node.js)<br>ask-richter.onrender.com"]
    end

    subgraph "Nuvem Supabase"
        SupabaseDB["üì¶ Supabase Storage<br>(√çndice FAISS)"]
    end

    subgraph "Servi√ßos de IA (Produ√ß√£o)"
        HF_API["ü§ó Hugging Face API<br>(LLM)"]
    end

    User -- "1\. Interage com a UI" --> Frontend
    Frontend -- "2\. Requisi√ß√£o API" --> Backend
    Backend -- "3\. Download do √çndice (na inicializa√ß√£o)" --> SupabaseDB
    Backend -- "4\. Busca de Contexto (em mem√≥ria)" --> faiss((FAISS))
    Backend -- "5\. Envia Prompt com Contexto" --> HF_API
    HF_API -- "6\. Retorna Resposta" --> Backend
    Backend -- "7\. Resposta para o Frontend" --> Frontend
    Frontend -- "8\. Exibe Resposta" --> User

    style User fill:#D6EAF8
    style Frontend fill:#E8DAEF
    style Backend fill:#D5F5E3
    style SupabaseDB fill:#FEF9E7
    style HF_API fill:#FDEDEC
```

O frontend hospedado na Vercel se comunica com o backend rodando no Render. O backend utiliza um √≠ndice FAISS armazenado no Supabase Storage para busca sem√¢ntica e interage com modelos de linguagem (Ollama localmente, Hugging Face em produ√ß√£o) para gerar respostas contextuais.

## üöÄ Deploy na Nuvem

### Vercel (Frontend)

O frontend √© implantado na Vercel, aproveitando seus recursos de CI/CD cont√≠nuo diretamente do reposit√≥rio GitHub.

* **Deploy Autom√°tico:** Qualquer push para a branch principal (ou conforme configurado) aciona um novo build e deploy na Vercel.
* **Vari√°veis de Ambiente:** A URL base da API do backend (Render) √© configurada como uma vari√°vel de ambiente (`NEXT_PUBLIC_API_BASE_URL`) nas configura√ß√µes do projeto na Vercel.
* **Build Ignorado (Opcional):** Para otimizar os builds, voc√™ pode configurar a Vercel para ignorar builds se apenas arquivos do backend forem modificados, usando as configura√ß√µes de "Ignored Build Step".

### Render (Backend)

O backend √© implantado no Render.com, uma plataforma de hospedagem de aplica√ß√µes e APIs.

* **Deploy Cont√≠nuo do Git:** O Render est√° configurado para monitorar a branch principal do reposit√≥rio e realizar um deploy autom√°tico em cada push.
* **Vari√°veis de Ambiente:** Vari√°veis de ambiente cruciais como `OPENAI_API_KEY`, `HUGGINGFACE_API_KEY`, `SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`, `SUPABASE_BUCKET_NAME` e `AI_PROVIDER` s√£o configuradas nas configura√ß√µes do servi√ßo no Render.
* **Health Check:** Um endpoint `/api/health` foi implementado para que o Render possa verificar a sa√∫de da aplica√ß√£o.
* **Escalabilidade:** O Render oferece op√ß√µes de escalabilidade vertical e horizontal conforme a necessidade da sua aplica√ß√£o.

### Supabase (Armazenamento)

O Supabase √© utilizado para hospedar o banco de dados PostgreSQL e, crucialmente, o Supabase Storage para armazenar o √≠ndice FAISS.

* **Supabase Storage:** Um bucket espec√≠fico (`faiss-index`) √© usado para armazenar os arquivos do √≠ndice vetorial. Pol√≠ticas de Row Level Security (RLS) foram configuradas para proteger o acesso aos arquivos, garantindo que apenas o backend autenticado possa interagir com eles.
* **Vari√°veis de Ambiente:** As credenciais de conex√£o com o Supabase (URL e chave de servi√ßo) s√£o armazenadas como vari√°veis de ambiente no backend (Render) para acesso seguro.



### üõ†Ô∏è Stack Tecnol√≥gica Completa

| Camada                        | Tecnologia           | Descri√ß√£o                                                                                                                                               |
| :---------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **üèóÔ∏è Arquitetura e Estrutura** | Turborepo            | Orquestrador de monorepo para otimizar os scripts de build, teste e desenvolvimento entre os workspaces.                                                |
|                               | npm Workspaces       | Gerenciamento de pacotes e depend√™ncias de forma isolada para cada aplica√ß√£o (`frontend`, `backend`) dentro do monorepo.                                |
| **‚öôÔ∏è Backend**                 | Node.js              | Ambiente de execu√ß√£o para o servidor, utilizando seu sistema de m√≥dulos ESM (`"type": "module"`).                                                       |
|                               | Express.js           | Framework minimalista para a constru√ß√£o da nossa API RESTful, incluindo as rotas `/api/chat` e `/api/health`.                                           |
|                               | TypeScript           | Linguagem principal do backend, garantindo seguran√ßa de tipos e um c√≥digo mais robusto e manuten√≠vel.                                                   |
|                               | tsx                  | Executor de TypeScript moderno e de alta performance, usado para rodar os scripts e o servidor em modo de desenvolvimento.                              |
| **‚öõÔ∏è Frontend**                | Next.js (App Router) | Framework React para a constru√ß√£o da interface de usu√°rio reativa, otimizada para performance e SEO.                                                    |
|                               | React (`useState`)   | Gerenciamento de estado manual e expl√≠cito para a interface do chat, garantindo controle total sobre o fluxo de dados.                                  |
|                               | Tailwind CSS         | Framework de CSS utility-first para a estiliza√ß√£o r√°pida e responsiva de toda a interface.                                                              |
|                               | Shadcn/ui            | Cole√ß√£o de componentes de UI modernos, acess√≠veis e customiz√°veis, utilizados para construir o layout do chat.                                          |
|                               | markdown-to-jsx      | Biblioteca utilizada para renderizar com seguran√ßa as respostas da IA, convertendo o texto Markdown em componentes React.                               |
| **üß† IA & Dados**              | FAISS (`faiss-node`) | Banco de dados vetorial em-mem√≥ria para buscas por similaridade sem√¢ntica de alta velocidade no contexto do CV.                                         |
|                               | OpenAI Embeddings    | Modelo `text-embedding-3-small` utilizado para converter os textos do CV em vetores num√©ricos (embeddings).                                             |
|                               | LangChain.js         | Utilizada para orquestrar o carregamento e a manipula√ß√£o do √≠ndice vetorial FAISS.                                                                      |
|                               | Ollama               | Provedor de LLM padr√£o para o ambiente de desenvolvimento, rodando modelos como `mistral:7b` localmente.                                                |
|                               | Hugging Face API     | Provedor de LLM alternativo para o ambiente de produ√ß√£o, permitindo o uso de modelos como o `Llama-3.1`.                                                |
| **‚òÅÔ∏è Nuvem & DevOps**          | Vercel               | Plataforma de CI/CD e hospedagem para o deploy do frontend Next.js, com builds autom√°ticos a cada `git push`.                                           |
|                               | Render.com           | Plataforma de CI/CD e hospedagem para o deploy do backend Node.js, configurado via `render.yaml` (Infrastructure as Code).                              |
|                               | Supabase Storage     | Servi√ßo de armazenamento de objetos (S3-compat√≠vel) utilizado para persistir o √≠ndice FAISS na nuvem, garantindo que ele n√£o se perca entre os deploys. |
|                               | GitHub               | Reposit√≥rio central do c√≥digo-fonte e gatilho para os pipelines de CI/CD da Vercel e do Render.                                                         |

## Arquitetura de Indexa√ß√£o e Consulta

O fluxo de dados √© projetado para ser simples e desacoplado, garantindo uma comunica√ß√£o eficiente entre o usu√°rio e o servi√ßo de IA.

```mermaid
---
config:
  theme: default
  look: handDrawn
---
flowchart TD
 subgraph subGraph0["Fase 1: Indexa√ß√£o (Processo √önico/Offline)"]
        A2("üß© Chunking<br>Fragmenta√ß√£o de Texto")
        A1("üìÑ Fonte de Dados<br>CV.md, Projetos.md")
        A3("üõ∞Ô∏è API de Embeddings<br>OpenAI text-embedding-3-small")
        A4("üß† Gera√ß√£o do √çndice<br>Arquivos FAISS")
        A5["‚òÅÔ∏è Armazenamento na Nuvem<br>Supabase Storage"]
  end
 subgraph subGraph1["Inicializa√ß√£o do Servidor (Uma vez)"]
        C1("üñ•Ô∏è Servidor Backend<br>Render.com")
        C2(("üß† √çndice FAISS em Mem√≥ria"))
  end
 subgraph subGraph2["Ciclo de Pergunta e Resposta"]
        B2("‚öôÔ∏è API Backend<br>Node.js")
        B1("üë§ Usu√°rio no Frontend<br>Vercel")
        B6("üß† Roteador de LLM")
        B7("ü§ñ Gera√ß√£o da Resposta")
  end
 subgraph subGraph3["Fase 2: Consulta (Online - Tempo Real)"]
        subGraph1
        subGraph2
  end
    A1 --> A2
    A2 --> A3
    A3 --> A4
    A4 -- Upload dos arquivos --> A5
    A5 -- Download do √≠ndice --> C1
    C1 -- Carrega para mem√≥ria --> C2
    B1 -- "1\. Envia Pergunta" --> B2
    B2 -- "2\. Gera Embedding da Pergunta" --> A3
    B2 -- "3\. Busca por Similaridade" --> C2
    C2 -- "4\. Retorna Contexto Relevante" --> B2
    B2 -- "5\. Monta Prompt Final" --> B6
    B6 -- "6a\. Ollama (Local)" --> B7
    B6 -- "6b\. Hugging Face (Produ√ß√£o)" --> B7
    B7 -- "7\. Retorna Texto Gerado" --> B2
    B2 -- "8\. Envia Resposta" --> B1
    subGraph2 --> subGraph3
    A5@{ shape: cyl}
    style subGraph1 fill:transparent
    style subGraph3 color:#000000

```

## ‚öôÔ∏è Rodando o Projeto Localmente

Para executar o projeto no seu ambiente de desenvolvimento, siga os passos abaixo.

#### 1\. Pr√©-requisitos

  * **Node.js:** Vers√£o LTS (recomenda-se usar um gerenciador como `nvm`).
  * **npm:** Vers√£o compat√≠vel com Node.js.
  * **Ollama:** A aplica√ß√£o requer o [Ollama](https://ollama.com/) instalado e rodando localmente.
      * Ap√≥s instalar, puxe o modelo de linguagem que usaremos por padr√£o:
        ```bash
        ollama pull mistral:7b
        ```

#### 2\. Instala√ß√£o

Clone o reposit√≥rio e instale todas as depend√™ncias do monorepo a partir da raiz. Usamos a flag `--legacy-peer-deps` para resolver conflitos de sub-depend√™ncias.

```bash
git clone https://github.com/lfrichter/ask-richter.git
cd ask-richter
npm install --legacy-peer-deps
```

#### 3\. Vari√°veis de Ambiente

O projeto precisa de dois arquivos de ambiente separados.

**Para o Backend:**
Navegue at√© a pasta do backend e crie seu arquivo `.env` a partir do exemplo.

```bash
cd apps/backend
cp .env.example .env
```

Agora, edite o arquivo `.env` e preencha **todas** as chaves obrigat√≥rias:

```env
# Chave da OpenAI (obrigat√≥ria para gerar os embeddings)
OPENAI_API_KEY="sk-..."

# Provedor de IA padr√£o. Mude para 'huggingface' se quiser usar a API externa.
AI_PROVIDER="ollama"

# Modelos a serem usados
OLLAMA_MODEL="mistral:7b"
HUGGINGFACE_MODEL="meta-llama/Llama-3.1-8B-Instruct:novita"

# URL da sua inst√¢ncia Ollama
OLLAMA_BASE_URL="http://localhost:11434"

# (Opcional) Chave da Hugging Face
HUGGINGFACE_API_KEY="hf_..."

# Credenciais do Supabase (obrigat√≥rias para o armazenamento do √≠ndice)
SUPABASE_URL="https://[SEU-ID-DO-PROJETO].supabase.co"
SUPABASE_SERVICE_ROLE_KEY="sua-chave-service-role-secreta-aqui"
SUPABASE_BUCKET_NAME="faiss-index"
```

**Para o Frontend:**
Volte para a raiz do projeto e navegue at√© a pasta do frontend para criar o arquivo `.env.local`.

```bash
cd ../../apps/frontend
cp .env.example .env.local
```

O conte√∫do do `.env.local` j√° deve estar correto para o ambiente local:

```env
NEXT_PUBLIC_API_BASE_URL=http://localhost:3001
```

#### 4. Gera√ß√£o do Banco Vetorial

Antes de iniciar a aplica√ß√£o pela primeira vez, voc√™ precisa gerar o √≠ndice FAISS e fazer o upload dele para o Supabase. A partir da **raiz do projeto**, execute:

```bash
npm run build-index --workspace=backend
```

O processo de indexa√ß√£o ser√° executado de duas formas, dependendo do seu ambiente.

**Modo 1: Gera√ß√£o Apenas Local (para Desenvolvimento)**

Neste modo, o √≠ndice √© criado na sua m√°quina e usado diretamente pelo backend. √â ideal para rodar o projeto localmente sem depend√™ncias externas.

!["Store Faiss.index"](https://i.imgur.com/KRuhmbs.png)

Certifique-se de que as vari√°veis de ambiente do Supabase (`SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`) **n√£o** estejam definidas no seu arquivo `apps/backend/.env`.

O script criar√° o √≠ndice no diret√≥rio `/tmp/faiss_index` e exibir√° um erro ao tentar fazer o upload para o Supabase, o que √© esperado. O servidor local usar√° esse √≠ndice automaticamente.

**Modo 2: Gera√ß√£o Local com Upload para o Supabase (para Produ√ß√£o/Deploy)**

Este modo √© usado para gerar o √≠ndice e envi√°-lo para um armazenamento persistente (Supabase Storage), de onde ele pode ser baixado por um ambiente de produ√ß√£o (ex: Render, Vercel).

!["Faiss.index in the Supabase"](https://i.imgur.com/h7KmEJY.png)

Adicione as vari√°veis `SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY` e `SUPABASE_BUCKET_NAME` ao seu arquivo `apps/backend/.env`.

O script criar√° o √≠ndice localmente e, em seguida, far√° o upload dos arquivos para o seu bucket no Supabase, tornando-os dispon√≠veis para download em ambientes de produ√ß√£o.

#### 5\. Execu√ß√£o

Com tudo configurado, inicie o ambiente de desenvolvimento completo a partir da **raiz do projeto**:

```bash
npm run dev
```

  * O frontend estar√° dispon√≠vel em `http://localhost:3000`.
  * O backend estar√° dispon√≠vel em `http://localhost:3001`.

## ü§ù Como Contribuir

Este √© um projeto pessoal, mas estou aberto a sugest√µes e melhorias. Para garantir a qualidade e a consist√™ncia do c√≥digo, por favor, siga as diretrizes detalhadas no nosso **[Guia de Contribui√ß√£o](https://www.google.com/search?q=CONTRIBUTING.md)**.

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
